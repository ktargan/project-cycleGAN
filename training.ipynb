{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIspoKRghaDp"
      },
      "source": [
        "# CycleGAN training Notebook\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIH30RvNkxPa"
      },
      "source": [
        "This notebook includes the preprocessing of the datasets, training loops and finally the training of a re-implementation of the CycleGAN by Zhu et al. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV1Ts7scgwkF",
        "outputId": "09d758c5-46cb-4ee5-b7b3-6717dcc1febf"
      },
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\r\u001b[K     |▌                               | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 20.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 10.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 9.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 7.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 71kB 7.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 7.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 245kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 256kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 266kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 276kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 286kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 296kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 307kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 317kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 327kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 337kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 348kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 358kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 368kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 378kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 389kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 399kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 409kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 419kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 430kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 440kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 450kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 460kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 471kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 481kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 491kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 501kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 512kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 522kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 532kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 542kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 552kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 563kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 573kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 583kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 593kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 604kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 614kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 624kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 634kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 645kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 655kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 665kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 675kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 686kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 696kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 706kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgxXGNHxtGSw"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import time \n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ_FhbBklJfr"
      },
      "source": [
        "## Importing modules from git repository\n",
        "\n",
        "In the following the git repository will be cloned for the current runtime. Alternatively the following lines can be uncommented to mount your google drive and clone the repository permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uojdUpRKw69I"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/gdrive\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9ANSpyZiIGm"
      },
      "source": [
        "To clone the git repository permanently navigate to the desired destination in google drive in the following line. If you clone the repository to your google drive, this cell needs to be executed only once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd8W8LNviHG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e1a97fb-b8b8-402d-ab81-d89c8758fdfd"
      },
      "source": [
        "#% cd \"insert path here\"\n",
        "!git clone \"https://github.com/ktargan/project-cycleGAN.git\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'project-cycleGAN'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 129 (delta 70), reused 79 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (129/129), 23.90 KiB | 499.00 KiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOHKyC9piccG"
      },
      "source": [
        "If you cloned the repository to your drive, make sure that you are working on the state of the repository that is most up-to-date by using git pull."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CjdLiMut-I7",
        "outputId": "1f85418b-5183-4ca0-bb0c-8b2bf59dc6ed"
      },
      "source": [
        "#navigate to git repository in drive\n",
        "#e.g. % cd /content/drive/MyDrive/project-cycleGAN/\n",
        "#! git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9tLcOwMip7R"
      },
      "source": [
        "Now we can import the required files from the repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13LShy1yJY95"
      },
      "source": [
        "sys.path.insert(0,\"/content/project-cycleGAN\")\n",
        "\n",
        "import losses\n",
        "import generator\n",
        "import discriminator\n",
        "from utils import buffer\n",
        "from utils import img_ops"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OWDTIM-hFiL"
      },
      "source": [
        "## Dataset\n",
        "In the cell below we download the dataset horse2zebra as provided by tensorflow. However, here different datasets can be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN3ddcl98GIb"
      },
      "source": [
        "train_horses, train_zebras, test_horses, test_zebras = tfds.load('cycle_gan/horse2zebra', \n",
        "                                                                 split = ['trainA','trainB', 'testA[:30]', 'testB[:30]'], \n",
        "                                                                 as_supervised=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v1pyLfKDaOX"
      },
      "source": [
        "## Input Pipeline\n",
        "\n",
        "Preprocess input images:\n",
        "- resizing images to smaller size\n",
        "- random changes by random crops and flipping\n",
        "- normalizing of images\n",
        "- shuffling\n",
        "- prefetching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQROY1UPoVcb"
      },
      "source": [
        "#Input pipeline: preprocess images \n",
        "\n",
        "#resize image to smaller size (faster computation and thus more manageable for the scope of the task)\n",
        "#firstly by simply resizing and secondly randomly cropping the resulting images (introduces variation)\n",
        "train_horses = train_horses.map(lambda image, label: tf.image.resize(image,[135,135]))\n",
        "train_zebras = train_zebras.map(lambda image, label: tf.image.resize(image,[135,135]))\n",
        "train_horses = train_horses.map(lambda image: tf.image.random_crop(image,[128,128,3]))\n",
        "train_zebras = train_zebras.map(lambda image: tf.image.random_crop(image,[128,128,3]))\n",
        "#randomly decide to mirror images (make sure that they do not all face the same direction for one class)\n",
        "train_horses = train_horses.map(lambda image: tf.image.random_flip_left_right(image))\n",
        "train_zebras = train_zebras.map(lambda image: tf.image.random_flip_left_right(image))\n",
        "# images are normalizied to [-1, 1]\n",
        "train_horses = train_horses.map(lambda image: (image/127.5)-1)\n",
        "train_zebras = train_zebras.map(lambda image: (image/127.5)-1)\n",
        "\n",
        "#Zhu et al. use a batchsize of 1\n",
        "train_horses = train_horses.shuffle(buffer_size = 1000)\n",
        "train_horses = train_horses.batch(1)\n",
        "landscape_dataset = train_horses.prefetch(8)\n",
        "\n",
        "train_zebras = train_zebras.shuffle(buffer_size = 1000)\n",
        "train_zebras = train_zebras.batch(1)\n",
        "fantasy_dataset = train_zebras.prefetch(8)\n",
        "\n",
        "\n",
        "#for the test dataset which we use to print images in the end\n",
        "#resize image to smaller size\n",
        "test_horses = test_horses.map(lambda image, label: tf.image.resize(image,[128,128]))\n",
        "test_zebras = test_zebras.map(lambda image, label: tf.image.resize(image,[128,128]))\n",
        "# iamges are normalizied to [-1, 1]\n",
        "test_horses = test_horses.map(lambda image: (image/127.5)-1)\n",
        "test_zebras = test_zebras.map(lambda image: (image/127.5)-1)\n",
        "\n",
        "test_horses = test_horses.batch(1)\n",
        "test_horses = test_horses.prefetch(8)\n",
        "\n",
        "test_zebras = test_zebras.batch(1)\n",
        "test_zebras = test_zebras.prefetch(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iV_isfOqlAD"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "Below we define the custom training steps for both the generators and discriminators. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKN5Sj7nHfQM"
      },
      "source": [
        "def training_step_discrim(discriminator, optimizer, images, generated_images):\n",
        "  # calculate the discriminator loss and apply gradients\n",
        "  with tf.GradientTape() as tape:\n",
        "    # feed real images into discriminator, get the predictions\n",
        "    real_image_predictions = discriminator(images)\n",
        "    \n",
        "    # feed fake images into discriminator, get the predictions\n",
        "    fake_image_predictions = discriminator(generated_images)\n",
        "    \n",
        "    #calculate adversarial loss\n",
        "    discr_loss = losses.discriminator_loss(fake_image_predictions, real_image_predictions)\n",
        "\n",
        "    gradients = tape.gradient(discr_loss, discriminator.trainable_variables)\n",
        "    \n",
        "  optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
        "  return discr_loss\n",
        "\n",
        "@tf.function\n",
        "def training_step_gen(generator_zebras, generator_horses, discriminator_zebras, discriminator_horses, \n",
        "                      images_zebras, images_horses, optimizer_zebras, optimizer_horses):\n",
        "  #clarification: generator_zebras generates zebra images from horses \n",
        "  #Calculate the loss for both generators and update the weights\n",
        "  with tf.GradientTape() as tape_horse, tf.GradientTape() as tape_zebra:\n",
        "    \n",
        "    #feed original images to generators\n",
        "    fake_images_zebras = generator_zebras(images_horses)\n",
        "    fake_images_horses = generator_horses(images_pattern)\n",
        "\n",
        "    #get the assigned predicition from the discriminators\n",
        "    fake_image_predictions_zebras = discriminator_zebras(fake_images_zebras)\n",
        "    fake_image_predictions_horses = discriminator_horses(fake_images_horses)\n",
        "\n",
        "    #calculate the adversarial generatorloss: \n",
        "    #did the discriminator recognize the images as generated?\n",
        "    gen_loss_zebras = losses.generator_loss(fake_image_predictions_zebras)\n",
        "    gen_loss_horses = losses.generator_loss(fake_image_predictions_horses)\n",
        "    \n",
        "    #pass the generetaed zebra images of generator_zebras to generator_horses \n",
        "    #(to see if it produces horse images close to the original image)\n",
        "    recreated_images_horses = generator_horses(fake_images_zebras)\n",
        "    recreated_images_zebras = generator_zebras(fake_images_horses)\n",
        "\n",
        "    #calculate cycle loss: the weighting factor lambda is set to 10\n",
        "    #how much does the original image differ from the the cycled image \n",
        "    cycle_loss_forward = losses.calc_cycle_loss(images_zebras, recreated_images_zebras, 10)\n",
        "    cycle_loss_backward = losses.calc_cycle_loss(images_horses, recreated_images_horses, 10)\n",
        "    total_cycle_loss = cycle_loss_forward + cycle_loss_backward\n",
        "\n",
        "    #give images from their target domain to the generators\n",
        "    # e.g. give zebra images to a zebra generator and then see if the output \n",
        "    #images are close to original images -> identity loss\n",
        "    same_images_reconstructed_zebras = generator_zebras(images_zebras)\n",
        "    same_images_reconstructed_horses = generator_horses(images_horses)\n",
        "\n",
        "    identity_loss_horses = losses.identity_loss(images_horses, same_images_reconstructed_horses, 10)\n",
        "    identity_loss_zebras = losses.identity_loss(images_zebras, same_images_reconstructed_zebras, 10)\n",
        "\n",
        "    # sum up the losses for each generator\n",
        "    # this means the respective generator and identity loss (for their domain)\n",
        "    # but also the complete cycle consistency loss!\n",
        "    total_loss_zebras = gen_loss_zebras + total_cycle_loss + identity_loss_zebras\n",
        "    total_loss_horses = gen_loss_horses + total_cycle_loss + identity_loss_horses\n",
        "\n",
        "    #update weights (by calculating gradients) of the currently trained generator\n",
        "    gradients_zebras = tape_zebra.gradient(total_loss_zebras, generator_zebras.trainable_variables)\n",
        "    gradients_horses = tape_horse.gradient(total_loss_horses, generator_horses.trainable_variables)\n",
        "\n",
        "  #update weights\n",
        "  optimizer_zebras.apply_gradients(zip(gradients_zebras, generator_zebras.trainable_variables))\n",
        "  optimizer_horses.apply_gradients(zip(gradients_horses, generator_horses.trainable_variables))\n",
        "\n",
        "  #return loss and generated images for the buffer\n",
        "  return total_loss_zebras, total_loss_horses, fake_images_zebras, fake_images_horses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fN6kElwS_ku"
      },
      "source": [
        "# used later on to compute duration of an epoch\n",
        "def timing(start):\n",
        "    now = time.time()\n",
        "    time_per_training_step = now - start\n",
        "    \n",
        "    return round(time_per_training_step, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCox1OzxjCzG"
      },
      "source": [
        "##Start the Training\n",
        "\n",
        "First generators and discriminators are initialized. For longer training we stored frequent checkpoints to be sure not to loose training progress. The code for this is still included but as comments. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLMizrg7sHLg"
      },
      "source": [
        "# We will train 2 generators and 2 discriminators\n",
        "# generator_horses learns to translate zebra to horse images - i.e. generates horse images\n",
        "generator_horses = generator.Generator()\n",
        "# generator_zebras learns to translate horse to zebra images\n",
        "generator_zebras = generator.Generator()\n",
        "\n",
        "#discriminator horses learns to distinguish between true horse images and generated ones\n",
        "# receptive field on the patchGAN is set to 70, to create 70x70 image patches\n",
        "discrim_horses = discriminator.Discriminator(70)\n",
        "# the other way round\n",
        "discrim_zebras = discriminator.Discriminator(70)\n",
        "\n",
        "#Zhu et al. use a learning rate of 0.0002 for the first 100 epochs and then start decreasing it\n",
        "#They keep the same learning rate for the first 100 epochs and linearly decay the rate to \n",
        "#zero over the next 100 epochs.\n",
        "#however due to computational reasons we only train for 100 epochs and thus keep \n",
        "#the learning rate stable\n",
        "learning_rate = 0.0002\n",
        "\n",
        "#optimizers for all models\n",
        "gen_horse_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "gen_zebra_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "disc_horse_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "disc_zebra_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "#create a folder to store checkpoints (here we store it in google drive to make sure \n",
        "#that all progress is saved permantently)\n",
        "\n",
        "#checkpoint_path = \"/content/gdrive/MyDrive/final_project_ANNwtf/checkpoints/discrim_pretraining\"\n",
        "#if not os.path.exists(checkpoint_path):\n",
        "#    os.makedirs(checkpoint_path)\n",
        "\n",
        "\n",
        "#create checkpoint manager and store model and optimizer state in case \"save\" is called\n",
        "#ckpt = tf.train.Checkpoint(generator_horses=generator_horses,\n",
        "#                           generator_zebras =generator_zebras,\n",
        "#                           discrim_horses=discrim_horses,\n",
        "#                           discrim_zebras=discrim_zebras,\n",
        "#                           gen_horse_optimizer=gen_horse_optimizer,\n",
        "#                           gen_zebra_optimizer=gen_zebra_optimizer,\n",
        "#                           disc_horse_optimizer=disc_horse_optimizer,\n",
        "#                           disc_zebra_optimizer=disc_zebra_optimizer)\n",
        "\n",
        "#ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
        "\n",
        "#if a checkpoint exists, restore the latest checkpoint.\n",
        "#if ckpt_manager.latest_checkpoint:\n",
        "#  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "#  print ('Latest checkpoint restored!')\n",
        "\n",
        "#initialize lists to save model losses in\n",
        "discrim_horse_losses = []\n",
        "discrim_zebra_losses = []\n",
        "gen_horse_losses = []\n",
        "gen_zebra_losses = []\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "#start the training\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"epoch: \", epoch+1, \" ----------------------------------------------------------\")\n",
        "\n",
        "  #create empty buffers to store generated images in (so that discriminator can use these in the training step)\n",
        "  #buffer is filled via the image_buffer function in the training steps\n",
        "  buffer_horse = buffer.Buffer(50)\n",
        "  buffer_zebra = buffer.Buffer(50)\n",
        "  \n",
        "  #fill buffers with random images\n",
        "  generated_img = tf.random.normal([50,128,128,3])\n",
        "  buffer_horse.set_image_buffer(generated_img)\n",
        "  buffer_zebra.set_image_buffer(generated_img)\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  #create variables to save averaged losses\n",
        "  running_gen_zebra_loss = 0\n",
        "  running_gen_horse_loss = 0\n",
        "  running_disc_zebra_loss = 0\n",
        "  running_disc_horse_loss = 0\n",
        "  running_average_factor = 0.95\n",
        "\n",
        "  #iterate through the datasets and train the models\n",
        "  for horse_img, zebra_img in tf.data.Dataset.zip((horse_dataset, zebra_dataset)):\n",
        "    #take generated/random images from buffer\n",
        "    gen_img_horsebuffer = buffer_horse.get_image_buffer()\n",
        "    gen_img_zebrabuffer = buffer_zebra.get_image_buffer()  \n",
        "\n",
        "    #calculate the losses for generators and discriminators:\n",
        "\n",
        "    #first, training step for the discriminators: check performance on real images and generated ones\n",
        "    disc_loss_zebra = training_step_discrim(discrim_zebras, disc_zebra_optimizer, zebra_img, gen_img_zebrabuffer)\n",
        "    disc_loss_horse = training_step_discrim(discrim_horses, disc_horse_optimizer, horse_img, gen_img_horsebuffer)\n",
        "    \n",
        "    #train the generators \n",
        "    gen_loss_zebra, gen_loss_horse, fake_images_zebra, fake_images_horse = training_step_gen(generator_zebras, generator_horses, \n",
        "                                          discrim_zebras, discrim_horses, zebra_img, \n",
        "                                          horse_img, gen_zebra_optimizer, gen_horse_optimizer)\n",
        "\n",
        "    #also save generated images in the respective buffers\n",
        "    buffer_zebra.set_image_buffer(fake_images_zebra)\n",
        "    buffer_horse.set_image_buffer(fake_images_horse)\n",
        "\n",
        "    #loss updates\n",
        "    running_gen_zebra_loss = running_average_factor* running_gen_zebra_loss + (1- running_average_factor)*gen_loss_zebra\n",
        "    running_gen_horse_loss = running_average_factor* running_gen_horse_loss + (1- running_average_factor)*gen_loss_horse\n",
        "\n",
        "    running_disc_zebra_loss = running_average_factor* running_disc_zebra_loss + (1- running_average_factor)*disc_loss_zebra\n",
        "    running_disc_horse_loss = running_average_factor* running_disc_horse_loss + (1- running_average_factor)*disc_loss_horse\n",
        "\n",
        "  #save losses in respective list\n",
        "  discrim_zebra_losses.append(running_disc_zebra_loss)\n",
        "  discrim_horse_losses.append(running_disc_horse_loss)\n",
        "\n",
        "  gen_zebra_losses.append(running_gen_zebra_loss)\n",
        "  gen_horse_losses.append(running_gen_horse_loss)\n",
        "\n",
        "  #print statements to check on current training state\n",
        "  print(f\"the training step and test evaluation took {timing(start)} seconds\")\n",
        "  print(\"generator_horse loss\", running_gen_horse_loss.numpy())\n",
        "  print(\"generator zebra loss\", running_gen_zebra_loss.numpy())\n",
        "  print(\"discriminator_horse loss\", running_disc_horse_loss.numpy())\n",
        "  print(\"discriminator_zebra loss\", running_disc_zebra_loss.numpy())\n",
        "\n",
        "  #every 5th epoch save a checkpoint\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "  #plot images after every epoch\n",
        "  img_ops.plot_image_cycle(generator_zebras,generator_horses, zebra_dataset, horse_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiCDkAnZ6eRO"
      },
      "source": [
        "#print first 30 pictures (to have comparable output for ablations studies)\n",
        "img_ops.plot_image_cycle(generator_zebras,generator_horses, test_zebras, test_horses, ablation = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}